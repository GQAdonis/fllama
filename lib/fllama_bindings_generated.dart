// ignore_for_file: always_specify_types
// ignore_for_file: camel_case_types
// ignore_for_file: non_constant_identifier_names

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
import 'dart:ffi' as ffi;

/// Bindings for `src/fllama.h`.
///
/// Regenerate bindings with `flutter pub run ffigen --config ffigen.yaml`.
///
class FllamaBindings {
  /// Holds the symbol lookup function.
  final ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
      _lookup;

  /// The symbols are looked up in [dynamicLibrary].
  FllamaBindings(ffi.DynamicLibrary dynamicLibrary)
      : _lookup = dynamicLibrary.lookup;

  /// The symbols are looked up with [lookup].
  FllamaBindings.fromLookup(
      ffi.Pointer<T> Function<T extends ffi.NativeType>(String symbolName)
          lookup)
      : _lookup = lookup;

  /// A longer lived native function, which occupies the thread calling it.
  ///
  /// Do not call these kind of native functions in the main isolate. They will
  /// block Dart execution. This will cause dropped frames in Flutter applications.
  /// Instead, call these native functions on a separate isolate.
  ffi.Pointer<ffi.Char> fllama_inference(
    fllama_inference_request request,
  ) {
    return _fllama_inference(
      request,
    );
  }

  late final _fllama_inferencePtr = _lookup<
      ffi.NativeFunction<
          ffi.Pointer<ffi.Char> Function(
              fllama_inference_request)>>('fllama_inference');
  late final _fllama_inference = _fllama_inferencePtr
      .asFunction<ffi.Pointer<ffi.Char> Function(fllama_inference_request)>();
}

final class fllama_inference_request extends ffi.Struct {
  @ffi.Int()
  external int num_threads;

  @ffi.Int()
  external int num_threads_batch;

  @ffi.Int()
  external int num_gpu_layers;

  /// Pointer to the input string
  external ffi.Pointer<ffi.Char> input;
}
